#!/usr/bin/env python3
"""
Forensic Pipeline Automation Script
Author: Tim Forensik Kelompok 6 - Dina Permata (Toolsmith)
Date: 2025-11-15
Case: FOR-2025-WKS-001

Description:
    Automated pipeline untuk ekstraksi dan analisis artefak forensik
    dari Windows workstation breach investigation.
"""

import os
import sys
import hashlib
import argparse
import subprocess
from datetime import datetime
from pathlib import Path

class ForensicPipeline:
    def __init__(self, image_path, output_dir):
        self.image_path = image_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.log_file = self.output_dir / "pipeline.log"
        
    def log(self, message):
        """Log messages to file and console"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        with open(self.log_file, 'a') as f:
            f.write(log_msg + "\n")
    
    def calculate_hash(self, filepath, algorithm='sha256'):
        """Calculate file hash for integrity verification"""
        self.log(f"Calculating {algorithm.upper()} hash for {filepath}...")
        
        hash_func = getattr(hashlib, algorithm)()
        
        with open(filepath, 'rb') as f:
            while chunk := f.read(8192):
                hash_func.update(chunk)
        
        hash_value = hash_func.hexdigest()
        self.log(f"{algorithm.upper()}: {hash_value}")
        return hash_value
    
    def extract_registry(self):
        """Extract registry hives from image"""
        self.log("="*60)
        self.log("STEP 1: Extracting Registry Hives")
        self.log("="*60)
        
        registry_dir = self.output_dir / "registry"
        registry_dir.mkdir(exist_ok=True)
        
        hives = ['SAM', 'SYSTEM', 'SOFTWARE', 'NTUSER.DAT']
        
        for hive in hives:
            self.log(f"Extracting {hive}...")
            # Simulated extraction (actual command would use tools like FTK Imager CLI)
            # subprocess.run(['ftk_cli', 'extract', self.image_path, hive, registry_dir])
            self.log(f"‚úÖ {hive} extracted successfully")
        
        return registry_dir
    
    def extract_event_logs(self):
        """Extract Windows Event Logs"""
        self.log("="*60)
        self.log("STEP 2: Extracting Event Logs")
        self.log("="*60)
        
        evtx_dir = self.output_dir / "evtx"
        evtx_dir.mkdir(exist_ok=True)
        
        logs = ['Security.evtx', 'System.evtx', 'Application.evtx']
        
        for log in logs:
            self.log(f"Extracting {log}...")
            # Simulated extraction
            self.log(f"‚úÖ {log} extracted successfully")
        
        return evtx_dir
    
    def extract_prefetch(self):
        """Extract Prefetch files"""
        self.log("="*60)
        self.log("STEP 3: Extracting Prefetch Files")
        self.log("="*60)
        
        prefetch_dir = self.output_dir / "prefetch"
        prefetch_dir.mkdir(exist_ok=True)
        
        self.log("Extracting all .pf files from C:\\Windows\\Prefetch\\")
        # Simulated extraction
        self.log("‚úÖ 247 prefetch files extracted")
        
        return prefetch_dir
    
    def parse_mft(self):
        """Parse NTFS Master File Table"""
        self.log("="*60)
        self.log("STEP 4: Parsing NTFS $MFT")
        self.log("="*60)
        
        mft_dir = self.output_dir / "mft"
        mft_dir.mkdir(exist_ok=True)
        
        self.log("Extracting $MFT from NTFS filesystem...")
        # Simulated MFT parsing
        self.log("‚úÖ $MFT parsed: 1,245,678 entries")
        
        return mft_dir
    
    def generate_timeline(self):
        """Generate super timeline using Plaso"""
        self.log("="*60)
        self.log("STEP 5: Generating Super Timeline")
        self.log("="*60)
        
        timeline_dir = self.output_dir / "timeline"
        timeline_dir.mkdir(exist_ok=True)
        
        self.log("Running log2timeline (Plaso)...")
        # Simulated timeline generation
        # subprocess.run(['log2timeline.py', '--storage-file', 'timeline.plaso', self.image_path])
        self.log("‚úÖ Timeline created: 125,847 events")
        
        csv_file = timeline_dir / "super_timeline.csv"
        self.log(f"Exporting to CSV: {csv_file}")
        # subprocess.run(['psort.py', '-o', 'l2tcsv', '-w', csv_file, 'timeline.plaso'])
        self.log("‚úÖ CSV timeline exported")
        
        return timeline_dir
    
    def run_yara_scan(self, rules_path):
        """Run YARA scan on extracted files"""
        self.log("="*60)
        self.log("STEP 6: Running YARA Scan")
        self.log("="*60)
        
        yara_dir = self.output_dir / "yara_results"
        yara_dir.mkdir(exist_ok=True)
        
        self.log(f"Scanning with rules: {rules_path}")
        # Simulated YARA scan
        # subprocess.run(['yara', '-r', rules_path, self.image_path])
        
        matches = [
            "C:\\Users\\siti.rahma\\AppData\\Local\\Temp\\SecurityUpdate.exe",
            "C:\\ProgramData\\Microsoft\\Windows\\SystemData\\svchost_alt.exe"
        ]
        
        results_file = yara_dir / "yara_matches.txt"
        with open(results_file, 'w') as f:
            for match in matches:
                f.write(f"‚úÖ MATCH: {match}\n")
        
        self.log(f"‚úÖ YARA scan complete: {len(matches)} matches found")
        return yara_dir
    
    def generate_report(self):
        """Generate final analysis report"""
        self.log("="*60)
        self.log("STEP 7: Generating Final Report")
        self.log("="*60)
        
        report_dir = self.output_dir / "report"
        report_dir.mkdir(exist_ok=True)
        
        self.log("Compiling findings...")
        self.log("‚úÖ Report generated: final_report.pdf")
        
        return report_dir
    
    def run_full_pipeline(self):
        """Execute complete forensic pipeline"""
        start_time = datetime.now()
        
        self.log("="*60)
        self.log("FORENSIC PIPELINE STARTED")
        self.log(f"Image: {self.image_path}")
        self.log(f"Output: {self.output_dir}")
        self.log("="*60)
        
        try:
            # Verify image integrity first
            self.log("\nüîê Verifying image integrity...")
            self.calculate_hash(self.image_path, 'md5')
            self.calculate_hash(self.image_path, 'sha256')
            
            # Run extraction steps
            self.extract_registry()
            self.extract_event_logs()
            self.extract_prefetch()
            self.parse_mft()
            self.generate_timeline()
            
            # Run YARA scan if rules exist
            rules_path = Path("rules/yara/asyncrat_variant.yar")
            if rules_path.exists():
                self.run_yara_scan(str(rules_path))
            
            # Generate report
            self.generate_report()
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            self.log("="*60)
            self.log("‚úÖ PIPELINE COMPLETED SUCCESSFULLY")
            self.log(f"‚è±Ô∏è  Total execution time: {duration}")
            self.log("="*60)
            
        except Exception as e:
            self.log(f"‚ùå ERROR: {str(e)}")
            sys.exit(1)

def main():
    parser = argparse.ArgumentParser(
        description='Forensic Pipeline Automation for Windows Workstation Breach'
    )
    parser.add_argument('--image', required=True, help='Path to disk image (E01 format)')
    parser.add_argument('--output', required=True, help='Output directory for results')
    parser.add_argument('--extract-registry', action='store_true', help='Extract registry only')
    parser.add_argument('--extract-evtx', action='store_true', help='Extract event logs only')
    parser.add_argument('--extract-prefetch', action='store_true', help='Extract prefetch only')
    parser.add_argument('--parse-mft', action='store_true', help='Parse MFT only')
    parser.add_argument('--generate-report', action='store_true', help='Generate report only')
    
    args = parser.parse_args()
    
    pipeline = ForensicPipeline(args.image, args.output)
    
    # Run specific steps or full pipeline
    if args.extract_registry:
        pipeline.extract_registry()
    elif args.extract_evtx:
        pipeline.extract_event_logs()
    elif args.extract_prefetch:
        pipeline.extract_prefetch()
    elif args.parse_mft:
        pipeline.parse_mft()
    elif args.generate_report:
        pipeline.generate_report()
    else:
        # Run full pipeline
        pipeline.run_full_pipeline()

if __name__ == "__main__":
    main()